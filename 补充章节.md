## X.1 模糊C均值聚类法

### 聚类
把性质相似的事物聚在一起形成一个类的过程

### 聚类方法
- 硬聚类法：K均值法聚类(K-means, KM)
- 软聚类法：模糊C均值聚类法(Fuzzy c-means, FCM)

### KM算法基本思想
把n个数据 $x_j (j=1, 2, ..., n)$ 分为m个类组 $H_i (i=1, 2, ..., m)$，并求每组 $H_i$ 的聚类中心 $c_i$，使目标函数J达到最小。

> 算法本身就是不断通过迭代的方式，通过优化代价函数J的寻找诸聚类中心 $c_i$ ，进一步明确各个元素所属的类别。

### 聚类中心
当前分类时每一类的数据的算数平均值。
假设类别Hi中元素的个数是 $|H_i|$，则聚类中心 $c_i = \frac{1}{|H_i|} \sum_{x \in H_i} x$

### 目标函数J
对当前分类结果的评价函数。如果函数值偏大，则分类结果较差；如果函数值较小，则分类结果较好。

> 可以用各个元素到聚类中心的欧几里得距离总和来构建J。$J=\sum_{i=1}^{m} \sum_{x \in H_{i}}\|x-c_{i}\|^{2}$

### 聚类中心和目标函数的初始化
KM是迭代算法，因此首先必须要对聚类中心进行初始化。
由于聚类的类别数m已知，因此常用的方法是从中任意选择m个元素作为聚类中心。
然后通过公式计算初始目标函数值。

$$
\begin{array}{l}
c_{i}^{(1)}=t_{i} \quad t_{i}=\operatorname{rand}(x) \\
J^{(1)}=\sum_{i=1}^{m} \sum_{x \in H_{i}}\left\|x-c_{i}^{(1)}\right\|^{2}
\end{array}
$$
> 上标(1)表示第1次迭代过程。

### 元素类别的划分
当进行第k次迭代计算时，得到了诸聚类中心 $c_{i}^{(k)}$，这样就可以计算每个元素x到诸聚类中心的距离 $d_{i}^{(k)}$。
x到哪一类中心的距离最短，则就把x划归到哪一类。

$$
\begin{array}{l}
d_{i}^{(k)}=\left\|x-c_{i}^{(k)}\right\| \\
d_{r}^{(k)}=\min \left\{d_{i}^{(k)}\right\} \\
x \in H_{r}^{(k)}
\end{array}
$$

### 聚类中心的更新
对所有元素x进行分类以后，每一个元素都有类别标签，此时需要根据这个标签更新聚类中心。并计算新的目标函数值。

$$
\begin{array}{l}
c_{i}^{(k+1)}=\frac{1}{\left|H_{i}^{(k)}\right|} \sum_{x \in H_{i}^{(k)}} x \\
J^{(k+1)}=\sum_{i=1}^{m} \sum_{x \in H_{i}^{(k)}}\left\|x-c_{i}^{(k+1)}\right\|^{2}
\end{array}
$$

### 迭代终止条件
(常用)：目标函数值几乎不再变化，这里使用足够小的正数δ来体现。
- if $|J^{(k+1)} - J^{(k)}| \le d$：退出迭代，输出每个元素的标签作为最终聚类结果
- else：继续循环计算距离并更新聚类中心和目标函数，直到终止条件满足为止。

### KM子程序的调用
MATLAB自带kmeans函数，常用调用方式如下：
```m
U = kmeans(x, m)
[U, c] = kmeans(x, m)
[U, c, sum_dist] = kmeans(x, m)
[U, c, sum_dist, dist] = kmeans(x, m)
```

### KM算法中的隶属度矩阵
最后对元素的聚类标签，实际上相当于生成一个隶属度矩阵，它是一个布尔矩阵。

### 目标函数的另一种形式
利用隶属度矩阵，目标函数J可写成另一种形式。
设元素j对于第i类的隶属度值是 $u_{ij}$，则有：
$$
\begin{array}{l}
J=\sum_{i=1}^{m} \sum_{j=1}^{n} u_{i j}\left\|x_{j}-c_{i}\right\|^{2} \\
\sum_{i=1}^{m} u_{i j}=1
\end{array}
$$

### 从KM算法到FCM算法
如果隶属度矩阵取值范围不是 $\{0, 1\}$ 而是 $[0, 1]$，就得到了FCM算法。
因此KM被称为硬聚类法，而FCM则是软聚类法。

### FCM算法的目标函数
其隶属度取值范围是 $[0, 1]$。$\alpha \in (1, +\infty)$是一个加权参数。
$$
\begin{array}{l}
J=\sum_{i=1}^{m} \sum_{j=1}^{n} u_{i j}^{\alpha}\left\|x_{j}-c_{i}\right\|^{2} \\
\sum_{i=1}^{m} u_{i j}-1=0 \quad \forall j=1,2, \ldots, n
\end{array}
$$
> 本质上就是在隶属度和为1的条件下求J的最小值。

### 拉格朗日目标函数构造
使用拉格朗日乘子法构建新的目标函数。这个函数中包括三类变量，$u_{ij}, c_i, \lambda_j$。
为了求出这个函数的最小值，需要对其中的每一个变量求偏导数，并使得偏导数等于0。
$$
\bar{J}=\sum_{i=1}^{m} \sum_{j=1}^{n} u_{i j}^{\alpha}\left\|x_{j}-c_{i}\right\|^{2}+\sum_{j=1}^{n} \lambda_{j}\left(\sum_{i=1}^{m} u_{i j}-1\right)
$$

### 聚类中心的更新公式
对聚类中心求偏导数，并令其为0.
$$
\begin{array}{l}
\frac{\partial \bar{J}}{\partial c_{i}}=2 \sum_{j=1}^{n} u_{i j}^{\alpha}\left(c_{i}-x_{j}\right)=0 \\
\Rightarrow c_{i}=\frac{\sum_{j=1}^{n} u_{i j}^{\alpha} x_{j}}{\sum_{j=1}^{n} u_{i j}^{\alpha}}
\end{array}
$$

### 隶属度的更新公式
对隶属度求偏导数，并令其为0，可以得到隶属度更新原始公式。
这个式子里含有参数 $\lambda_j$，必须进一步消掉。
$$
\begin{array}{l}
\frac{\partial \bar{J}}{\partial u_{i j}}=\alpha\left\|x_{j}-c_{i}\right\|^{2} u_{i j}^{\alpha-1}+\lambda_{j}=0 \\
\Rightarrow u_{i j}=\left(\frac{-\lambda_{j}}{\alpha\left\|x_{j}-c_{i}\right\|^{2}}\right)^{\frac{1}{\alpha-1}}
\end{array}
$$

把这个表达式代入约束条件中，有：
$$
\begin{array}{l}
\because \sum_{i=1}^{m} u_{i j}=1 \quad u_{i j}=\left(\frac{-\lambda_{j}}{\alpha\left\|x_{j}-c_{i}\right\|^{2}}\right)^{\frac{1}{\alpha-1}} \\
\therefore \sum_{i=1}^{m}\left(\frac{-\lambda_{j}}{\alpha\left\|x_{j}-c_{i}\right\|^{2}}\right)^{\frac{1}{\alpha-1}}=\left(\frac{-\lambda_{j}}{\alpha}\right)^{\frac{1}{\alpha-1}} \sum_{i=1}^{m}\left(\frac{1}{\left\|x_{j}-c_{i}\right\| \frac{2}{\alpha-1}}\right)=1
\end{array}
$$

$$
\begin{array}{l}
\left(\frac{-\lambda_{j}}{\alpha}\right)^{\frac{1}{\alpha-1}} \sum_{i=1}^{m}\left(\frac{1}{\left\|x_{j}-c_{i}\right\| \frac{2}{\alpha-1}}\right)=1 \\
\Rightarrow\left(\frac{-\lambda_{j}}{\alpha}\right)^{\frac{1}{\alpha-1}}=\frac{1}{\sum_{i=1}^{m}\left(\frac{1}{\left\|x_{j}-c_{i}\right\| \frac{2}{\alpha-1}}\right)}=\frac{1}{\sum_{k=1}^{m}\left(\frac{1}{\left\|x_{j}-c_{k}\right\| \frac{2}{\alpha-1}}\right)}
\end{array}
$$

代回更新公式，避免变量冲突，将求和变量改为k。
$$
\begin{array}{l}
u_{i j}=\left(\frac{-\lambda_{j}}{\alpha\left\|x_{j}-c_{i}\right\|^{2}}\right)^{\frac{1}{\alpha-1}}=\left(\frac{-\lambda_{j}}{\alpha}\right)^{\frac{1}{\alpha-1}} \cdot \frac{1}{\left\|x_{j}-c_{i}\right\|^{\frac{2}{\alpha-1}}} \\
=\frac{1}{\sum_{k=1}^{m}\left(\frac{1}{\left\|x_{j}-c_{k}\right\|^{\frac{2}{\alpha-1}}}\right)} \cdot \frac{1}{\left\|x_{j}-c_{i}\right\|^{\frac{2}{\alpha-1}}} \\
=\frac{1}{\sum_{k=1}^{m}\left(\frac{\left\|x_{j}-c_{i}\right\|}{\left\|x_{j}-c_{k}\right\|}\right)^{\frac{2}{\alpha-1}}}
\end{array}
$$

### 更新公式总结
在FCM迭代循环中，聚类中心和隶属度两者用以下公式更新。
在实际操作中，可以通过随机数生成一批初始隶属度，然后不断更新。

$$
c_{i}=\frac{\sum_{j=1}^{n} u_{i j}^{\alpha} x_{j}}{\sum_{j=1}^{n} u_{i j}^{\alpha}} \quad u_{i j}=\frac{1}{\sum_{k=1}^{m}\left(\frac{\left\|x_{j}-c_{i}\right\|}{\left\|x_{j}-c_{k}\right\|}\right)^{\frac{2}{\alpha-1}}}
$$

### FCM的MATLAB实现
```m
[center, U, obj_fcn] = FCM(x, m, options);
[center, U, obj_fcn] = FCM(x, m);
```

其中options是一个4×1列向量，诸分量含义如下：
- options(1)：隶属度指数α>1
- options(2)：最大迭代次数
- options(3)：隶属度最小变化量，迭代终止条件
- options(4)：每次迭代是否输出信息标志
- 当options缺省时，默认值为：(2,100,10^(-5),1)。

### 随机数据的生成和显示
平面随机点的生成，需要生成一定范围内的随机横坐标和纵坐标。这里可以使用rand或者其类似函数。
直接使用plot函数并附加对应的符号就可以描绘批量散点而不划线。
疏密不一致的散点，只需进行多次叠加即可。

#### 语法
```m
X = rand
X = rand(n)
X = rand(sz1,...,szN)
X = rand(sz)
X = rand(___,typename)
X = rand(___,"like",p)
X = rand(s,___)
```

#### 说明
X = rand 返回从区间 (0,1) 的均匀分布中得到的随机标量。

#### 示例
X = rand(n) 返回一个由均匀分布的随机数组成的 n×n 矩阵。
- X = rand(sz1,...,szN) 返回由随机数组成的 sz1×...×szN 数组，其中 sz1,...,szN 指示每个维度的大小。例如：rand(3,4) 返回一个 3×4 的矩阵。
- X = rand(sz) 返回由随机数组成的数组，其中大小向量 sz 定义 size(X)。例如：rand([3 4]) 返回一个 3×4 的矩阵。
- X = rand(___,typename) 返回由 typename 数据类型的随机数组成的数组。typename 输入可以是 "single" 或 "double"。您可以使用上述语法中的任何输入参数。
- X = rand(___,"like",p) 返回一个与 p 类似的由随机值组成的数组，它具有与 p 相同的数据类型和复/实性（实数或复数）。您可以指定 typename 或 "like"，但不能同时指定两者。
- X = rand(s,___) 从随机数流 s 而不是默认全局流生成数字。要创建一个流，请使用 RandStream。您可以指定 s，后跟上述语法中的任意输入参数组合。

### 算法讨论
- FCM算法是一种收敛算法，而随着数据数量、分布复杂度和聚类数量的增加，同等条件下的收敛速率也可能会变慢（并非绝对）。
- 对于正态分布的数据来说，FCM算法收敛快，且分类效果良好，但聚类数目必须合适，否则适得其反；而对于无规律分布的孤立点（也叫做野点）比较敏感，容易造成错分类。

### FCM算法在不同领域的拓展
- 在图像处理领域，FCM算法需要结合图像的邻域信息不断更新，例如给目标函数后加上一项邻域信息约束，从而得到对应的聚类中心和隶属度更新公式。
- 在大数据处理领域，FCM算法需要被加速运行，同时保证其精确度不能有过多的丢失。因此要从算法层面对FCM的公式进行优化，还需要要使用并行计算的硬件（如GPU）加速运行。
